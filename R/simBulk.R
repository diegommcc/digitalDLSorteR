#' @import ggplot2
NULL


################################################################################
####################### Generate cell composition matrix #######################
################################################################################

#' Generate training and test cell composition matrix.
#'
#' Generate training and test cell composition matrices for the simulation of
#' bulk samples with known cell composition using single-cell expression
#' profiles. The resulting matrix will determine the proportion of the different
#' cell types that will form the simulated bulk samples.
#'
#' First of all, simulated single-cell profiles are split into training and test
#' subsets (2/3 for training and 1/3 for test by default). Then, to avoid biases
#' due to the composition of bulk samples, proportions for the mixtures (bulk
#' samples) of cell types (\eqn{w_1,...,w_k}, where \eqn{k} is the number of
#' cell types available in single-cell profiles), are randomly generated using
#' five different approaches:
#'
#' \enumerate{ \item Cell proportions are randomly sampled from a truncated
#' uniform distribution with predefined limits according to a priori knowledge
#' of the abundance of each cell type (see \code{prob.design} argument). This
#' information ban be inferred from the single cell analysis itself or from the
#' literature. \item A second set is generated by randomly permuting cell type
#' labels from a distribution generated by the previous method. \item Cell
#' proportions are randomly sampled as by method 1 without replacement. \item
#' Using the last method for generating proportions, cell types labels are
#' randomly sampled. \item Cell proportions are randomly sampled from a
#' Dirichlet distribution. }
#'
#' If you want to see the distribution of cell type proportions generated by
#' each method during the process, you can access them with
#' \code{\link{showProbPlot}} function (see examples).
#'
#' It is important to note that the number of bulk-samples simulated are
#' determined in this step. You can predefine the number of bulk profiles
#' generated using \code{num.bulk.samples} argument. By default, the number of
#' bulk samples generated depends on the number of single-cell profiles
#' available: approximately 18 more samples will be formed than there are cells
#' in \code{single.cell.final}. We recommend set a number of 30000 samples. This
#' number will be split in training and test data: 60% for training and 40% for
#' evaluating the model.
#'
#' @param object \code{DigitalDLSorter} object with \code{single.cell.real} and
#'   \code{zinb.params} slots.
#' @param cell.type.column Name or number of the column in cells metadata
#'   corresponding with the cell type of each cell.
#' @param prob.design \code{data.frame} with the frequency ranges expected for
#'   each cell type present in the experiment. This information can be estimated
#'   from literature or from the single-cell experiment itself. This
#'   \code{data.frame} must be built by three columns with specific headers:
#'   \itemize{ \item A cell type column with the same name of the cell type
#'   column in cells.metadata. If the name of the column is not the same,
#'   function returns an error. Cell types must appear on cells.metadata. \item
#'   A second column named 'from' with the start frequency for each cell type.
#'   \item A third column named 'to' with the final frequency for each cell
#'   type.}
#' @param proportions.train Vector of five integer numbers that determine the
#'   proportions of bulk samples that will be generated by the methods explained
#'   in details in train samples. This vector represents proportions, so they
#'   must add 100 and none can be less than 1. By default, a majority of random
#'   samples without using predefined ranges will be generated.
#' @param proportions.test As \code{proportions.train} for test samples.
#' @param train.freq Proportion of cells used for training set (2/3 by default).
#' @param n.cells Number of cells that are aggregated in order to simulate one
#'   bulk RNA-seq sample (100 by default).
#' @param num.bulk.samples Integer which allows to establish the number of bulk
#'   samples that will be generated taking into account training and test data.
#'   If it is NULL (by default), approximately 18 more samples will be formed
#'   than there are cells in \code{single.cell.final} slot.
#' @param exclusive.types Vector of cell types which allows to establish cell
#'   types that biologically do not make sense to be mixed during the generation
#'   of bulk samples. Some samples presents this exclusive cell types. If it is
#'   equal to NULL (by default), all cell types will be mixed when generating
#'   bulk samples.
#' @param verbose Show informative messages during the execution.
#'
#' @return A \code{\link{DigitalDLSorter}} object with \code{prob.cell.types}
#'   slot containing a \code{\link{ProbMatrixCellTypes}} object. For more
#'   information about the structure of this class, see
#'   \code{\link{ProbMatrixCellTypes}}. The most important element is the cell
#'   composition matrix, which is formed by \eqn{n} rows (being \eqn{n} the
#'   number of bulk samples that will be generated) and \eqn{k} columns (being
#'   \eqn{k} the number of cell types present in the experiment).
#'
#' @export
#'
#' @seealso \code{\link{generateBulkSamples}} \code{\link{ProbMatrixCellTypes}}
#'
#' @examples
#' ## generate a data.frame with frequency ranges of each cell type
#' probMatrix <- data.frame(
#'   Cell_type = c("ER+", "HER2+", "ER+ and HER2+", "TNBC",
#'                  "Stromal", "Monocyte", "Tme", "BGC",
#'                  "Bmem", "DC", "Macrophage", "TCD8", "Treg"),
#'   from = c(rep(30, 4), 1, rep(0, 8)),
#'   to = c(rep(70, 4), 50, rep(15, 8))
#' )
#' DDLSSmallCompleted <- generateTrainAndTestBulkProbMatrix(
#'   object = DDLSSmallCompleted,
#'   cell.type.column = "Cell_type",
#'   prob.design = probMatrix,
#'   num.bulk.samples = 200,
#'   verbose = TRUE
#' )
#'
#' @references Torroja, C. y Sánchez-Cabo, F. (2019). digitalDLSorter: A Deep
#' Learning algorithm to quantify immune cell populations based on scRNA-Seq
#' data. Frontiers in Genetics 10, 978. doi: \url{10.3389/fgene.2019.00978}
#'
generateBulkCellMatrix <- function(
  object,
  cell.ID.column,
  cell.type.column,
  prob.design,
  proportions.train = c(10, 5, 20, 15, 10, 40),
  proportions.test = c(10, 5, 20, 15, 10, 40),
  train.freq.cells = 2/3,
  train.freq.bulk = 0.6,
  balanced.cells = FALSE,
  n.cells = 100,
  num.bulk.samples = NULL,
  exclusive.types = NULL,
  verbose = TRUE
) {
  if (class(object) != "DigitalDLSorter") {
    stop("The object provided is not of DigitalDLSorter class")
  } else if (is.null(single.cell.real(object))) {
    stop("'single.cell.real' slot is empty")
  } else if (!train.freq.cells <= 0.95 || !train.freq.cells >= 0.05) {
    stop("'train.seq.cells' argument must be less than or equal to 0.95 and greater than or equal to 0.05")
  } else if (!train.freq.bulk <= 0.95 || !train.freq.bulk >= 0.05) {
    stop("'train.seq.bulk' argument must be less than or equal to 0.95 and greater than or equal to 0.05")
  } else if (!is.data.frame(prob.design)) {
    stop(paste("prob.design must be a data.frame with three column names:",
               "cell.type.column: must be equal to cell.type.column in cells.metadata (colData slot of single.cell.final)",
               "from: frequency from which the cell type can appear",
               "to: frequency up to which the cell type can appear", sep = "\n   - "))
  } else if (sum(abs(proportions.train)) != 100 ||
             sum(abs(proportions.test)) != 100) {
    stop("Proportions provided must add up to 100")
  # } else if (any(proportions.train <= 0) || any(proportions.test <= 0)) {
  #   stop("Proportions can not be equal to or lesser than zero")
  } else if (length(proportions.train) != 6 || length(proportions.train) != 6) {
    stop("Proportions must be a vector of six elements")
  } else if (is.null(num.bulk.samples) || missing(num.bulk.samples)) {
    stop("'num.bulk.samples' argument must be provided")
  }
  if (!is.null(prob.cell.types(object)) || !length(prob.cell.types(object)) == 0) {
    warning("'prob.cell.types' slot already has the probability matrices. Note that it will be overwritten\n\n",
            call. = FALSE, immediate. = TRUE)
  }
  if (!all(unlist(lapply(X = list(proportions.train, proportions.test),
                         FUN = function(x) all(x == floor(x)))))) {
    stop("Proportions provided must be composed by integer")
  }
  
  if (!is.null(single.cell.simul(object))) {
    # extract data from SCE to list
    list.metadata <- list(
      single.cell.real(object) %>% 
        SingleCellExperiment::colData(),
      single.cell.simul(object) %>% 
        SingleCellExperiment::colData()
    )
    # check if cell.type.column is correct
    lapply(
      X = list(list.metadata[[1]], list.metadata[[2]]),
      FUN = function(x) {
        .checkColumn(
          metadata = x,
          ID.column = cell.type.column,
          type.metadata = "cells.metadata",
          arg = "cell.type.column"
        )
      }
    )
    list.metadata[[1]]$simCellName <- paste(
      list.metadata[[1]][, cell.type.column], 
      list.metadata[[1]][, cell.ID.column], sep = "_"
    )
    list.metadata[[1]]$Simulated <- FALSE
    cells.metadata <- S4Vectors::rbind(list.metadata[[1]], list.metadata[[2]])  
  } else {
    cells.metadata <- single.cell.real(object) %>% 
      SingleCellExperiment::colData()
  }
  # check if prob.design is correctly built
  lapply(X = c(cell.type.column, "from", "to"),
         FUN = function(x) {
           .checkColumn(
             metadata = prob.design,
             ID.column = x,
             type.metadata = "prob.design",
             arg = ""
           )
         }
  )
  if (any(duplicated(prob.design[, cell.type.column]))) {
    stop(paste("prob.design must not contain duplicated cell types in",
               cell.type.column, "column"))
  } else if (!all(prob.design[, cell.type.column] %in%
                  unique(cells.metadata[, cell.type.column]))) {
    stop("There are some cell types in prob.design that does not appear in cells.metadata. Check that the prob.design matrix is correctly built")
  } else if (any(prob.design$from < 0) || any(prob.design$from > 99)) {
    stop("'from' column in prob.design must be greater than or equal to 0 and lesser than or equal to 99")
  } else if (any(prob.design$to < 1) || any(prob.design$to > 100)) {
    stop("'to' column in prob.design must be greater than or equal to 1 and lesser than or equal to 100")
  } else if (any(prob.design$from > prob.design$to)) {
    stop("'from' entries must be lesser than 'to' entries")
  } else if (any(abs(prob.design$from) + abs(prob.design$to) > 100)) {
    stop("The sum between the 'from' and 'to' entries must not be greater than 100")
  }
  ## check if n.cells is invalid
  if (n.cells <= 0) {
    stop("n.cells must be greater than zero")
  } else if (n.cells < length(unique(cells.metadata[, cell.type.column]))) {
    stop("n.cells must be equal to or greater than the number of cell types in",
         " experiment. In any case, we recommend greater than 100 cells per", 
         " bulk sample")
  }
  # check proportions --> avoid num.bulk.samples too low
  total.train <- ceiling(num.bulk.samples * train.freq.bulk)
  total.test <- num.bulk.samples - total.train
  if (total.test == 0) 
    stop("'num.bulk.samples' too low in relation with 'train.freq.bulk'")
  nums.train <- .setHundredLimit(
    ceiling((total.train * proportions.train) / 100),
    limit = total.train
  )
  nums.test <- .setHundredLimit(
    ceiling((total.test * proportions.test) / 100),
    limit = total.test
  )
  if (verbose) {
    message(paste("\n=== The number of bulk samples that will be generated has been fixed to",
                  num.bulk.samples))  
  }
  # split data into training and test sets
  cells <- rownames(cells.metadata) # [, cell.ID.column]
  names(cells) <- cells.metadata[, cell.type.column]
  # train set: 
  # balanced.cells == TRUE --> same number of cells by cell types
  # balanced.cells == FALSE --> completely random
  if (!balanced.cells) {
    train.set <- sample(cells, size = round(nrow(cells.metadata) * train.freq.cells))
    if (length(unique(names(train.set))) != length(unique(names(cells)))) {
      train.set <- sapply(
        X = unique(names(cells)), 
        FUN = function(x, cells, train.freq.cells) {
          sample(cells[names(cells) == x], 
                 size = round(length(cells[names(cells) == x]) * train.freq.cells))
        }, cells = cells, train.freq.cells
      ) %>% unname() %>% unlist()  
    }
  } else {
    train.set <- sapply(
      X = unique(names(cells)), 
      FUN = function(x, cells, train.freq.cells) {
        sample(cells[names(cells) == x], 
               size = round(length(cells[names(cells) == x]) * train.freq.cells))
      }, cells = cells, train.freq.cells
    ) %>% unname() %>% unlist()
  }
  train.types <- names(train.set)
  train.set.list <- list()
  # sort cell types in order to speed up reading times in HDF5 files --> 
  # same order as are stored simulated cells in HDF5 file
  if (!is.null(zinb.params(object))) {
    model.cell.types <- grep(pattern = cell.type.column,
                             x = colnames(zinb.params(object)@model@X),
                             value = T)
    cell.type.names <- sub(pattern = cell.type.column,
                           replacement = "",
                           x = model.cell.types)
    if (any(levels(factor(train.types)) %in% cell.type.names)) {
      cell.type.names <- c(
        cell.type.names,
        setdiff(levels(factor(train.types)), cell.type.names)
      )
    }
  } else {
    cell.type.names <- levels(factor(train.types))
  }
  # print(levels(factor(train.types)))
  cell.type.train <- cell.type.names[cell.type.names %in% levels(factor(train.types))]
  print(cell.type.train)
  for (ts in cell.type.train) {
    train.set.list[[ts]] <- train.set[train.types == ts]
  }
  # test set
  test.set <- cells[!cells %in% train.set]
  test.types <- names(test.set)
  test.set.list <- list()
  cell.type.test <- cell.type.names[cell.type.names %in% levels(factor(test.types))]
  print(cell.type.test)
  for (ts in cell.type.test) {
    test.set.list[[ts]] <- test.set[test.types == ts]
  }
  
  # checkear si todos los tipos celulares aparecen en ambos tests. En el caso de
  # que no, o aplico la forma balanceada o lo resuelvo heurísticamente?

  if (verbose) {
    message("\n=== Train Set cells by type:")
    tb <- unlist(lapply(train.set.list, length))
    message(paste0("    - ", names(tb), ": ", tb, collapse = "\n"), "\n")
    message("=== Test Set cells by type:")
    tb <- unlist(lapply(test.set.list, length))
    message(paste0("    - ", names(tb), ": ", tb, collapse = "\n"), "\n")
  }

  prob.list <- apply(
    X = prob.design, MARGIN = 1,
    FUN = function (x) {
      return(seq(from = x['from'], to = x['to']))
    }
  )
  names(prob.list) <- prob.design[, cell.type.column]

  # check if there are exclusive types
  if (!is.null(exclusive.types)) {
    if (length(exclusive.types) < 2) {
      stop("'exclusive.types' must be at least 2 different cell types")
    } else if (any(duplicated(exclusive.types))) {
      stop("'exclusive.types' can not contain duplicated elements")
    } else if (!all(exclusive.types %in% unique(cells.metadata[, cell.type.column]))) {
      stop("Cell types present in exclusive.types argument must be present in cells.metadata")
    }
    message("=== Setting the next exclusive cell types in some bulk samples: ",
            paste(exclusive.types, collapse = ", "), "\n")
    index.ex <- match(exclusive.types, names(prob.list))
  } else {
    index.ex <- NULL
  }
  n.cell.types <- length(unique(train.types))
  functions.list <- list(.generateSet1, .generateSet2, .generateSet3,
                         .generateSet4, .generateSet5, .generateSet6)

  # TRAIN SETS -----------------------------------------------------------------
  excl.cell.type <- c(index.ex, index.ex, NULL, NULL, index.ex, NULL)
  train.prob.matrix <- matrix(rep(0, n.cell.types), nrow = 1, byrow = T)
  train.plots <- list()
  n <- 1
  first <- TRUE
  for (fun in functions.list) {
    if (nums.train[n] == 0) {
      n <- n + 1
      next
    }
    train.probs <- fun(
      prob.list = prob.list,
      prob.matrix = train.prob.matrix,
      num = nums.train[n],
      s.cells = total.train,
      n.cell.types = n.cell.types,
      index.ex = excl.cell.type[n]
    )
    train.prob.matrix <- rbind(train.prob.matrix, train.probs)
    if (first) {
      train.prob.matrix <- train.prob.matrix[-1, , drop = FALSE]
      first <- FALSE
    }
    train.plots[[n]] <- .plotsQCSets(
      probs = train.probs,
      prob.matrix = train.prob.matrix,
      n = n,
      set = "train"
    )
    n <- n + 1
  }
  # check if matrix is correctly built
  if (is.null(dim(train.prob.matrix))) 
    train.prob.matrix <- matrix(train.prob.matrix, nrow = 1)
  if (is.null(colnames(train.prob.matrix)))
    colnames(train.prob.matrix) <- prob.design[, cell.type.column]
  
  rownames(train.prob.matrix) <- paste("Bulk", seq(dim(train.prob.matrix)[1]),
                                       sep = "_")
  train.plots <- train.plots[!unlist(lapply(train.plots, is.null))]
  
  if (verbose) {
    message("=== Probability matrix for training data:")
    message(paste(c("    - Bulk samples:", "    - Cell types:"),
                  dim(train.prob.matrix),
                  collapse = "\n"), "\n")
  }
  # TEST SETS ------------------------------------------------------------------
  test.prob.matrix <- matrix(rep(0, n.cell.types), nrow = 1, byrow = T)
  test.plots <- list()
  n <- 1
  first <- TRUE
  for (fun in functions.list) {
    if (nums.test[n] == 0) {
      n <- n + 1
      next
    }
    test.probs <- fun(
      prob.list = prob.list,
      prob.matrix = test.prob.matrix,
      num = nums.test[n],
      s.cells = total.test,
      n.cell.types = n.cell.types,
      index.ex = excl.cell.type[n]
    )
    test.prob.matrix <- rbind(test.prob.matrix, test.probs)
    if (first && nums.test[n] != 0) {
      test.prob.matrix <- test.prob.matrix[-1, ]
      first <- FALSE
    }
    test.plots[[n]] <- .plotsQCSets(
      probs = test.probs,
      prob.matrix = test.prob.matrix,
      n = n,
      set = "test"
    )
    n <- n + 1
  }
  # check if matrix is correctly built
  if (is.null(dim(test.prob.matrix))) 
    test.prob.matrix <- matrix(test.prob.matrix, nrow = 1)
  if (is.null(colnames(test.prob.matrix)))
    colnames(test.prob.matrix) <- prob.design[, cell.type.column]
  
  rownames(test.prob.matrix) <- paste("Bulk", seq(dim(test.prob.matrix)[1]),
                                      sep = "_")
  test.plots <- test.plots[!unlist(lapply(test.plots, is.null))]
  
  if (verbose) {
    message("=== Probability matrix for test data:")
    message(paste(c("    - Bulk samples:", "    - Cell types:"),
                  dim(test.prob.matrix),
                  collapse = "\n"), "\n")
  }
  # GENERATE PROBS MATRIX NAMES ------------------------------------------------
  train.prob.matrix.names <- t(apply(
    X = train.prob.matrix,
    MARGIN = 1,
    FUN = setCount,
    setList = train.set.list,
    sn = colnames(train.prob.matrix),
    n.cells = n.cells
  ))

  test.prob.matrix.names <- t(apply(
    X = test.prob.matrix,
    MARGIN = 1,
    FUN = setCount,
    setList = test.set.list,
    sn = colnames(test.prob.matrix),
    n.cells = n.cells
  ))

  # generate object of ProbMatrixCellTypes class
  train.prob.matrix.object <- new(
    Class = "ProbMatrixCellTypes",
    prob.matrix = train.prob.matrix,
    cell.names = train.prob.matrix.names,
    set.list = train.set.list,
    set = train.set,
    exclusive.types = exclusive.types,
    plots = train.plots,
    type.data = "train"
  )
  test.prob.matrix.object <- new(
    Class = "ProbMatrixCellTypes",
    prob.matrix = test.prob.matrix,
    cell.names = test.prob.matrix.names,
    set.list = test.set.list,
    set = test.set,
    exclusive.types = exclusive.types,
    plots = test.plots,
    type.data = "test"
  )
  prob.cell.types(object) <- list(
    train = train.prob.matrix.object,
    test = test.prob.matrix.object
  )

  message("DONE")
  return(object)
}


.violinPlot <- function(df, title, x = CellType, y = Prob) {
  plot <- ggplot(df, aes(x = {{x}}, y = {{y}})) +
    geom_violin() + ggtitle(title) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
  return(plot)
}

.boxPlot <- function(df, title, x = CellType, y = Prob) {
  plot <- ggplot(df, aes(x = {{x}}, y = {{y}})) +
    geom_boxplot() + ggtitle(title) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
  return(plot)
}

.linesPlot <- function(df, title, x = CellType, y = Prob, group = Sample) {
  plot <- ggplot(df,aes(x = {{x}}, y = {{y}}, group = {{group}})) +
    geom_line(colour = "grey60") + ggtitle(title) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
  return(plot)
}

.plotsQCSets <- function(probs, prob.matrix, n, set) {
  title <- paste0("Bulk Probability Dist. Set ", n, " (", set, ")")
  n.samples <- paste("# samples:", dim(probs)[1])
  plots.functions <- list(.violinPlot, .boxPlot, .linesPlot)
  df <- reshape2::melt(probs)
  colnames(df) <- c("Sample", "CellType", "Prob")
  # first three plots
  plot.list <- lapply(plots.functions, function(f) f(df, paste(title, n.samples)))
  # final plots
  dummy <- t(apply(as.matrix(prob.matrix), 1, sort, decreasing = T))
  df <- reshape2::melt(dummy)
  colnames(df) <- c("Sample", "nMix", "Prob")
  df$nMix <- factor(df$nMix)
  plot.list[[4]] <- .boxPlot(df = df, x = nMix, title = title)
  names(plot.list) <- c("violinplot", "boxplot", "linesplot", "nmix")
  return(plot.list)
}


setCount <- function(x, setList, sn, n.cells) {
  names(x) <- sn
  sc <- c()
  x.set <- .setHundredLimit(x = (x * n.cells) / 100, limit = n.cells)
  for (cType in names(x)) {
    n <- ceiling(x.set[cType])
    # n <- ceiling(x[cType])
    if (n > 0) {
      repl <- ifelse(n > length(setList[[cType]]), TRUE, FALSE)
      sc <- c(sc, sample(setList[[cType]], size = n, replace = repl))
    }
  }
  return(sc[seq(n.cells)])
}

.cellExcluder <- function(vec, index.ex) {
  sel <- sample(index.ex, length(index.ex) - 1)
  vec[sel] <- 0
  return(list(vec, sel))
}

.setHundredLimit <- function(
  x, 
  index.ex = NULL, 
  limit = 100
) {
  if (sum(x) > limit) {
    while (TRUE) {
      if (is.null(index.ex)) {
        sel <- sample(seq(length(x)), 1)
      } else {
        sel <- sample(seq(length(x))[-index.ex], 1)
      }
      res <- x[sel] - abs(sum(x) - limit)
      if (res < 0) res <- x[sel] - sample(x[sel], 1)
      if (res >= 0) break
    }
    x[sel] <- res
  } else if (sum(x) < limit) {
    while (TRUE) {
      if (is.null(index.ex)) {
        sel <- sample(seq(length(x)), 1)
      } else {
        sel <- sample(seq(length(x))[-index.ex], 1)
      }
      res <- x[sel] + abs(sum(x) - limit)
      if (res <= limit) break
    }
    x[sel] <- res
  }
  if (sum(x) != limit) 
    return(.setHundredLimit(x = x, index.ex = index.ex, limit = limit))
  else 
    return(x)
}


.adjustHundred <- function(
  x,
  prob.list,
  index.ex = NULL,
  sampling = TRUE
) {
  # w <- rowMedians(as.matrix(prob.design[ind, c("from", "to")]))
  w <- unlist(lapply(prob.list, sample, 1))
  # remove cell types if needed
  if (!is.null(index.ex)) {
    x.list <- .cellExcluder(vec = x, index.ex = index.ex)
    x <- x.list[[1]]
    w[x.list[[2]]] <- 0
  }
  d <- abs(sum(x) - 100)
  if (sum(x) > 100) {
    div.w <- (w / sum(w)) * d
    while (!all(x >= div.w)) {
      index <- which(!x >= div.w)
      w[index] <- 0
      div.w <- (w / sum(w)) * d
    }
    x <- round(x - div.w)
    x <- .setHundredLimit(x = x, index.ex = index.ex)
  } else if (sum(x) < 100) {
    div.w <- (w / sum(w)) * d
    while (!all(100 - div.w > x)) {
      index <- which(!100 - div.w > x)
      w[index] <- 0
      div.w <- (w / sum(w)) * d
    }
    x <- round(x + div.w)
    x <- .setHundredLimit(x = x, index.ex = index.ex)
  }
  return(x)
}


.generateSet1 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  if (!is.null(index.ex)) {
    sampling <- function(prob.list) {
      x <- .cellExcluder(
        vec = unlist(lapply(X = prob.list, FUN = sample, 1)),
        index.ex = index.ex
      )
      return(x[[1]])
    }
  } else {
    sampling <- function(prob.list) unlist(lapply(X = prob.list, FUN = sample, 1))
  }
  # n <- ceiling(num * s.cells / 1000)
  n <- num
  while (dim(prob.matrix)[1] <= n) {
    prob.matrix <- rbind(prob.matrix, sampling(prob.list = prob.list))
  }
  prob.matrix <- prob.matrix[-1, , drop = FALSE]
  prob.matrix <- round(prob.matrix * 100 / rowSums(prob.matrix))
  prob.matrix <- t(apply(
    X = prob.matrix, MARGIN = 1, FUN = .setHundredLimit, index.ex
  ))
  return(prob.matrix)
}


.generateSet2 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  probs <- list()
  # n <- ceiling(num * s.cells/1000)
  n <- num
  while (length(probs) < n) {
    probs[[length(probs) + 1]] <- unlist(lapply(X = prob.list, FUN = sample, 1))
  }
  probs <- lapply(X = probs, FUN = function(x) return(round(x * 100 / sum(x))))
  probs <- lapply(X = probs, FUN = sample)
  probs <- lapply(X = probs, FUN = function(x) x[names(prob.list)])
  probs <- matrix(unlist(probs), nrow = n, byrow = T)
  probs <- t(apply(X = probs, 1, FUN = function(x) {
    .adjustHundred(x = x,
                   prob.list = prob.list,
                   index.ex = index.ex
    )
  }))
  colnames(probs) <- colnames(prob.matrix)
  return(probs)
}

.generateSet3 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  if (!is.null(index.ex)) {
    sampling <- function(p) {
      p <- .cellExcluder(vec = sample(p), index.ex = index.ex)
      return(p[[1]])
    }
  } else {
    sampling <- function(p) sample(p)
  }
  probs <- list()
  # n <- ceiling(num * s.cells/1000)
  n <- num
  while (length(probs) < n) {
    p <- rep(0, n.cell.types)
    i <- 1
    while (sum(p) < 100) {
      p[i] <- p[i] + sample(seq(100 - sum(p)), size = 1)
      i <- i + 1
      if (i > n.cell.types) {
        i <- 1
      }
    }
    p <- sampling(p)
    if (sum(p == 0) < n.cell.types) {
      probs[[length(probs) + 1]] <- p
    }
  }
  probs <- matrix(unlist(probs), nrow = n, byrow = T)
  colnames(probs) <- colnames(prob.matrix)
  probs <- round(probs * 100 / rowSums(probs))
  if (any(rowSums(probs) != 100))
    probs <- t(apply(X = probs, MARGIN = 1, FUN = .setHundredLimit, index.ex))
  return(probs)
}


.generateSet4 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  probs <- list()
  # n <- ceiling(num * s.cells/1000)
  n <- num
  while(length(probs) < n) {
    p <- rep(0, n.cell.types)
    names(p) <- names(prob.list)
    i <- 1
    while (sum(p) < 100) {
      dp <- 101
      while (dp > max(prob.list[[i]])) {
        dp <- sample(prob.list[[i]], size = 1)
      }
      p[i] <- dp
      i <- i + 1
      if (i > n.cell.types) i <- 1
    }
    p[1] <- p[1] + 1
    p <- sample(p)
    if (sum(p == 0) < n.cell.types) {
      probs[[length(probs) + 1]] <- p
    }
  }
  # probs <- lapply(X = probs, FUN = function(x) return(x[names(prob.list)]))
  probs <- matrix(unlist(probs), nrow = n, byrow = T)
  colnames(probs) <- colnames(prob.matrix)
  probs <- round(probs * 100 / rowSums(probs))
  if (any(rowSums(probs) != 100)) {
    probs <- t(apply(X = probs, MARGIN = 1,
                     FUN = function(x) {
                       .adjustHundred(
                         x = x,
                         prob.list = prob.list,
                         index.ex = index.ex
                       )
                     }))  
  }
  
  return(probs)
}


.generateSet5 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  probs <- list()
  # n <- ceiling(num * s.cells/1000)
  n <- num
  while(length(probs) < n) {
    p <- rep(0, n.cell.types)
    names(p) <- names(prob.list)
    i <- 1
    while (sum(p) < 100) {
      dp <- sample(prob.list[[i]], size = 1)
      p[i] <- dp
      i <- i + 1
      if (i > n.cell.types) i <- 1
    }
    p[1] <- p[1] + 1
    p <- sample(p)
    if (sum(p == 0) < n.cell.types) {
      probs[[length(probs) + 1]] <- p
    }
  }
  probs <- lapply(X = probs, FUN = sample)
  probs <- matrix(unlist(probs), nrow = n, byrow = T)
  colnames(probs) <- colnames(prob.matrix)
  probs <- round(probs * 100 / rowSums(probs))
  if (any(rowSums(probs) != 100)) {
    probs <- t(apply(X = probs, MARGIN = 1,
                     FUN = function(x) {
                       .adjustHundred(
                         x = x,
                         prob.list = prob.list,
                         index.ex = index.ex
                       )
                     }))
  }
  return(probs)
}

.generateSet6 <- function(
  prob.list,
  prob.matrix,
  num,
  s.cells,
  n.cell.types,
  index.ex
) {
  # n <- ceiling(num * s.cells/1000)
  n <- num
  if (!is.null(index.ex)) {
    generator <- function() {
      gtools::rdirichlet(
        n = 1,
        alpha = .cellExcluder(rep(1, n.cell.types), index.ex = index.ex)[[1]]
      )
    }
    probs <- t(replicate(n = n, expr = generator(), simplify = TRUE))
  } else {
    probs <- gtools::rdirichlet(n, rep(1, n.cell.types))
  }
  probs <- round(probs * 100)
  if (any(rowSums(probs) != 100)) {
    probs <- t(apply(X = probs, MARGIN = 1,
                     FUN = function(x) .setHundredLimit(
                       x = x, index.ex = index.ex
                     )))  
  }
  colnames(probs) <- colnames(prob.matrix)
  return(probs)
}



################################################################################
######################## Generate bulk RNA-seq samples #########################
################################################################################

#' Generate training and test simulated bulk RNA-seq samples.
#'
#' Generate training and test bulk profiles using the cell composition matrix
#' built by \code{\link{generateTrainAndTestBulkProbMatrix}} function. These
#' samples are generated using the assumption that the expression of gene
#' \eqn{i} in sample \eqn{j} is given by the sum of the cell type specific
#' expression \eqn{X_{ijk}} weighted by the proportions of cell type \eqn{k} in
#' the sample determined by the probability matrix. In practice, as described in
#' Torroja et al., 2019, these profiles are generated by the summation of 100
#' cells from different cell types determined by cell composition matrix. The
#' number of bulk samples is determined by dimensions of cell composition
#' matrix. See \code{\link{generateTrainAndTestBulkProbMatrix}} for details.
#'
#' \code{digitalDLSorteR} allows the use of HDF5 files as back-end for the
#' resulting data using \code{DelayedArray} and \code{HDF5Array} packages in
#' cases of generating too large bulk expression matrix. This functionality
#' allows you to work without keeping the data loaded in memory, which will be
#' of vital importance during some computationally heavy steps such as neural
#' network training. You must provide a valid file path in \code{file.backend}
#' argument to store the resulting file with '.h5' extension. The data will be
#' accessible from R without being loaded into memory. This option slightly
#' slows down execution times, since subsequent transformations of data will be
#' carried out by chunks instead of using all data. We recommend this option due
#' to the large size of the simulated matrices.
#'
#' @param object \code{DigitalDLSorter} object with \code{single.cell.final} and
#'   \code{prob.cell.types} slots.
#' @param type.data Type of data to generate among 'train', 'test' or 'both'
#'   (the last by default).
#' @param file.backend Valid file path where to save the HDF5 file used as
#'   backend. If it is equal to \code{NULL} (by default), the data are produced
#'   and loaded in memory.
#' @param threads Number of threads used during the generation of bulk samples
#'   (2 by default).
#' @param compression.level The compression level used if file.backend provided
#'   (6 by default). It is an integer value between 0 (no compression) and 9
#'   (highest and slowest compression).
#' @param verbose Show informative messages during the execution.
#'
#' @return A \code{\link{DigitalDLSorter}} object with \code{bulk.simul} slot
#'   containing a list with one or two entries (depending on selected
#'   \code{type.data} argument): 'train' and 'test'. Each entry contains a
#'   \code{SummarizedExperiment} object with simulated bulk samples in
#'   \code{assay} slot, sample names in \code{colData} slot and feature names in
#'   \code{rowData} slot.
#'
#' @export
#'
#' @seealso \code{\link{generateTrainAndTestBulkProbMatrix}}
#'   \code{\link{ProbMatrixCellTypes}}
#'
#' @examples
#' ## loading all data in memory
#' DDLSSmallCompleted <- generateBulkSamples(
#'   DDLSSmallCompleted,
#'   threads = 2,
#'   type.data = "both"
#' )
#' \dontrun{
#' ## using HDF5 as backend
#' DDLSChung <- generateBulkSamples(
#'   DDLSChung,
#'   threads = 2,
#'   type.data = "both",
#'   file.backend = "DDLSChung.bulk.simul.h5"
#' )
#' }
#'
#' @references Pagès H, Hickey wcfP, Lun A (2020). DelayedArray: A unified
#' framework for working transparently with on-disk and in-memory array-like
#' datasets. R package version 0.14.1.
#'
#' Pagès H (2020). HDF5Array: HDF5 backend for DelayedArray objects. R package
#' version 1.16.1.
#'
simBulkSamples <- function(
  object,
  type.data = "both",
  file.backend = NULL,
  compression.level = NULL,
  block.processing = FALSE,
  block.size = 1000,
  chunk.dims = NULL,
  threads = 1,
  verbose = TRUE
) {
  if (class(object) != "DigitalDLSorter") {
    stop("The object provided is not of DigitalDLSorter class")
  } else if (is.null(single.cell.simul(object)) && 
             is.null(single.cell.real(object))) {
    stop("The are not single-cell profiles in DigitalDLSorter object")
  } else if (is.null(prob.cell.types(object))) {
    stop("'prob.cell.types' slot is empty")
  } else if (!any(type.data == c("train", "test", "both"))) {
    stop("type.data argument must be one of the next options: train, test or both")
  }
  if (!is.null(file.backend)) {
    if (file.exists(file.backend)) {
      stop("file.backend already exists. Please provide a correct file path")
    }
    if (is.null(compression.level)) {
      compression.level <- HDF5Array::getHDF5DumpCompressionLevel()
    } else {
      if (compression.level < 0 || compression.level > 9) {
        stop("compression.level must be an integer between 0 (no compression) ",
             "and 9 (highest and slowest compression). ")
      }
    }
    
  }
  if (threads <= 0) {
    threads <- 1
  }
  if (verbose) {
    message(paste("=== Set parallel environment to", threads, "threads"))
  }
  
  if (type.data == "both") {
    if (!is.null(object@bulk.simul)) {
      warning("'bulk.simul' slot will be overwritten\n\n",
              call. = FALSE, immediate. = TRUE)
    }
    bulk.counts <- lapply(
      X = c("train", "test"),
      FUN = function(x) {
        if (verbose) {
          message(paste("\n=== Generating", x, "bulk samples:"))
        }
        .generateBulkProfiles(
          object = object,
          type.data = x,
          file.backend = file.backend,
          compression.level = compression.level,
          block.processing = block.processing,
          block.size = block.size,
          chunk.dims = chunk.dims,
          threads = threads,
          verbose = verbose
        )
      }
    )
    names(bulk.counts) <- c("train", "test")
    object@bulk.simul <- bulk.counts
  } else {
    if (!is.null(object@bulk.simul) && type.data %in% names(object@bulk.simul)) {
      warning(paste(type.data, "data in 'bulk.simul' slot will be overwritten", 
                    "\n\n"),
              call. = FALSE, immediate. = TRUE)
    }
    if (verbose) {
      message(paste("\n=== Generating", type.data, "bulk samples:"))
    }
    bulk.counts <- .generateBulkProfiles(
      object = object,
      type.data = type.data,
      file.backend = file.backend,
      compression.level = compression.level,
      block.processing = block.processing,
      block.size = block.size,
      chunk.dims = chunk.dims,
      threads = threads,
      verbose = verbose
    )
    if (!is.null(bulk.simul(object))) {
      if (type.data %in% names(bulk.simul(object))) {
        bulk.simul(object, type.data) <- NULL
      }
      bulk.simul(object) <- c(bulk.simul(object), type.data = bulk.counts)
    } else {
      bulk.simul(object) <- list(bulk.counts)
      names(bulk.simul(object)) <- type.data
    }
  }
  message("\nDONE")
  return(object)
}

.generateBulkProfiles <- function(
  object,
  type.data,
  file.backend,
  compression.level,
  block.processing,
  block.size,
  chunk.dims,
  threads,
  verbose
) {
  sel.bulk.cells <- prob.cell.types(object, type.data) %>% cell.names()
  sel.bulk.cells <- sel.bulk.cells[sample(nrow(sel.bulk.cells)), ]
  pattern <- paste0(colnames(prob.cell.types(object, type.data) %>% 
                               prob.matrix()), "_S", 
                    collapse = "|")
  if (block.processing && is.null(file.backend)) {
    stop("'block.processing' is only compatible with the use of HDF5 files ", 
         "as back-end ('file.backend' argument)")
  } else if (block.processing && !is.null(file.backend)) {
    n <- nrow(sel.bulk.cells)
    J <- nrow(assay(single.cell.real(object)))
    if (n < block.size) {
      block.size <- n
      warning("The number of simulated samples is lesser than 'block.size'. ",
              "Only one block will be performed.", 
              call. = FALSE, immediate. = TRUE)
    }
    if (is.null(chunk.dims) || length(chunk.dims) != 2) chunk.dims <- c(J, 128)
    if (!file.exists(file.backend)) rhdf5::h5createFile(file.backend)
    rhdf5::h5createDataset(
      file.backend, type.data, 
      dims = c(J, block.size), 
      maxdims = c(J, n), 
      chunk = chunk.dims,
      storage.mode = "double"
    )
    r.i <- 0
    ## iteration over cells 
    for (iter in seq(ceiling(n / block.size))) {
      if ((block.size * iter) - n > 0) {
        dif <- (block.size * iter) - n
        block.size <- block.size - dif
      } else {
        dif <- block.size
      }
      sub.i <- seq(from = r.i + 1, to = r.i + block.size)
      r.i <- r.i + block.size
      if (threads == 1) {
        bulk.samples <- apply(
          X = sel.bulk.cells[sub.i, ],
          MARGIN = 1,
          FUN = .setBulk,
          object = object,
          pattern = pattern
        )  
      } else {
        bulk.samples <- pbapply::pbapply(
          X = sel.bulk.cells[sub.i, ],
          MARGIN = 1,
          FUN = .setBulk,
          object = object,
          pattern = pattern,
          cl = threads
        ) 
      }
      if (iter == 1) {
        rhdf5::h5write(
          obj = bulk.samples, file = file.backend, 
          name = type.data, level = compression.level
        )
      } else {
        # check number of cells in the next loop
        rhdf5::h5set_extent(file.backend, type.data, dims = c(J, n))
        rhdf5::h5write(
          obj = bulk.samples, 
          file = file.backend, name = type.data, 
          index = list(seq(J), seq((dif * (iter - 1)) + 1, 
                                   (dif * (iter - 1)) + ncol(bulk.samples))),
          level = compression.level
        )
      }
      if (verbose) message(paste("   - Block", iter, "written"))
    }
    rhdf5::H5close()
    # HDF5Array object for SingleCellExperiment class
    bulk.samples <- HDF5Array::HDF5Array(file = file.backend, name = type.data)
    dimnames(bulk.samples) <- list(rownames(assay(single.cell.real(object))), 
                                   rownames(sel.bulk.cells))
  } else if (!block.processing) {
    bulk.samples <- pbapply::pbapply(
      X = sel.bulk.cells,
      MARGIN = 1,
      FUN = .setBulk,
      object = object,
      pattern = pattern,
      cl = threads
    )
  }
  return(
    .createSEObject(
      counts = bulk.samples,
      samples.metadata = prob.cell.types(object, type.data)@prob.matrix[
        rownames(sel.bulk.cells), ],
      genes.metadata = rownames(assay(single.cell.real(object))),
      file.backend = file.backend,
      compression.level = compression.level,
      block.processing = block.processing,
      type.data = type.data,
      verbose = verbose
    )
  )
}

.createSEObject <- function(
  counts, 
  samples.metadata, 
  genes.metadata,
  file.backend,
  compression.level,
  block.processing,
  type.data,
  verbose
) {
  # could be a check of counts class -> if (is(counts, "HDF5Array"))
  if (!is.null(file.backend) && !block.processing) {
    counts <- .useH5backend(
      counts = counts,
      file.backend = file.backend,
      compression.level = compression.level,
      group = type.data,
      sparse = FALSE,
      verbose = verbose
    )
  }
  return(
    SummarizedExperiment::SummarizedExperiment(
      assays = list(counts = counts),
      colData = samples.metadata,
      rowData = genes.metadata
    )
  )
}

.setBulk <- function(x, object, pattern) {
  sep.b <- grepl(pattern = pattern, x = x)
  if (any(sep.b)) {
    cols <- match(x[sep.b], colnames(single.cell.simul(object))) %>% sort()
    sim.counts <- as.matrix(counts(single.cell.simul(object))[, cols])
    real.counts <- as.matrix(counts(single.cell.real(object))[, x[!sep.b]])
    counts <- .mergeMatrices(x = real.counts, y = sim.counts) # merge matrices
  } else if (all(sep.b)) {
    cols <- match(x[sep.b], colnames(single.cell.simul(object))) %>% sort()
    counts <- as.matrix(counts(single.cell.simul(object))[, cols])
  } else {
    counts <- as.matrix(counts(single.cell.real(object))[, x])
  }
  return(rowSums(edgeR::cpm.default(counts)))  
}
